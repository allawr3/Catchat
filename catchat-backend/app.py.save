from fastapi.middleware.cors import CORSMiddleware
import os
from fastapi import FastAPI, HTTPException
import openai
from dotenv import load_dotenv
from pydantic import BaseModel

# Load API key from .env file
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("Error: OPENAI_API_KEY not found. Check your .env file!")

# Initialize OpenAI API with legacy client
openai.api_key = OPENAI_API_KEY

# Initialize FastAPI
app = FastAPI(title="Catchat Backend")

# Add CORS middleware to allow cross-origin requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://www.qcatchat.com"],  # Allow only requests from this origin
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],  # Allow the HTTP methods you want to support
    allow_headers=["*"],  # Allow all headers
)

# Define request model for chat completions
class ChatCompletionRequest(BaseModel):
    model: str = "gpt-4"
    messages: list
    temperature: float = 0.7
    max_tokens: int = 200

@app.get("/")
def read_root():
    return {"message": "Welcome to Catchat!"}

@app.get("/chat/{user_input}")
async def chat(user_input: str):
    try:
        # Send the user input to GPT-4 using the legacy API format
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": user_input},
            ],
            temperature=0.7,
            max_tokens=200
        )

        # Get the bot response with the legacy format
        bot_reply = response['choices'][0]['message']['content'].strip()
        return {"response": bot_reply}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Add a proper POST endpoint for chat completions
@app.post("/v1/chat/completions")
async def chat_completions(request_data: ChatCompletionRequest):
    try:
        # Forward the request to OpenAI using the legacy format
        response = openai.ChatCompletion.create(
            model=request_data.model,
            messages=request_data.messages,
            temperature=request_data.temperature,
            max_tokens=request_data.max_tokens
        )

        # Return the original response format
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

